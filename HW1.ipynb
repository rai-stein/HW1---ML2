{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "yRxF3fGk83TKVLrMatsfF6",
     "type": "MD"
    }
   },
   "source": [
    "# <u>Submission instructions</u>\n",
    "### Submission in pairs unless otherwise authorized\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> This notebook contains all the questions. You should follow the instructions below.</li>\n",
    "<li> Solutions for both theoretical and practical parts should be provided in this notebook</li>\n",
    "</ul>\n",
    "\n",
    "<h3> Moodle submission</h3>\n",
    "\n",
    "\n",
    "<p style=\"font-size: 17px\">\n",
    "You should submit three files:\n",
    "</p>\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li>IPYNB notebook:\n",
    "  <ul>\n",
    "  <li>All the wet and dry parts, including code, graphs, discussion, etc.</li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li>PDF file:\n",
    "  <ul>\n",
    "  <li>Export the notebook to PDF. Make sure that all the cells are visible.</li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li>Pickle files:\n",
    "  <ul>\n",
    "    <li>As requested in Q3.2.a and Q4.a</li>\n",
    "  </ul>\n",
    "</li>\n",
    "</ul>\n",
    "<p style=\"font-size: 17px\">\n",
    "All files should be in the following format: \"HW1_ID1_ID2.file\"\n",
    "<br>\n",
    "Good Luck!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (15pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned in the lecture and tutorial that neural networks, thanks to their non-linear activation functions, can express a much wider range of functions than just linear ones. \n",
    "\n",
    "In each of the following exercises, you are given the weight matrices, biases and activations of a small neural network. Express the network's output as a simplified, well-known mathematical function and provide a short explanation. There is no need to prove correctness, an intuitive explanation is enough.\n",
    "\n",
    "The activation function (non-linearity) is denoted as $g$. The output is given by: \n",
    "\n",
    "$$s = W_2 g(W_1 x + b_1) + b_2.$$ \n",
    "\n",
    "In network 4, we also apply the activation to the final output, meaning the network's output is $g(s)$. When not stated otherwise, the bias vector is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 1\n",
    "\n",
    "$$x \\in \\mathbb{R}. \\quad W_1=\\begin{pmatrix} 1 \\\\ -1\\end{pmatrix}, W_2 = \\begin{pmatrix} 1 & 1\\end{pmatrix}. \\quad g=\\text{ReLU}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2\n",
    "\n",
    "$$x \\in \\mathbb{R}^2. \\quad W_1 = \\begin{pmatrix}-1 & 1 \\\\ 1 & 0 \\\\ -1 & 0\\end{pmatrix}, W_2 = \\begin{pmatrix}1 & 1 & -1\\end{pmatrix}. \\quad g=\\text{ReLU}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 3\n",
    "\n",
    "$$x=\\begin{pmatrix}x_1 \\\\ x_2 \\\\ y_1 \\\\ y_2\\end{pmatrix} \\in \\mathbb{R}^4. \\quad W_1 = \\begin{pmatrix} 1 & 0 & -1 & 0 \\\\ -1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & -1 \\\\ 0 & -1 & 0 & 1\\end{pmatrix}, W_2 = \\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}. \\quad g = \\text{ReLU}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 4 \n",
    "\n",
    "Here, the non-linearity is applied also to the output of the second layer. For simplicity, assume $ \\forall x \\ge 10, \\text{sigmoid}(x) = 1, \\text{sigmoid}(-x) = 0$.\n",
    "\n",
    "$$x \\in \\{0, 1\\}^2 \\quad \\text{(binary vector)}.$$ \n",
    "\n",
    "$$W_1 = \\begin{pmatrix} 20 & 20 \\\\ -20 & -20 \\end{pmatrix}, b_1 = \\begin{pmatrix} -10 \\\\ 30 \\end{pmatrix}, W_2 = \\begin{pmatrix} 20 & 20 \\end{pmatrix}, b_2 = -30. \\quad g=\\text{sigmoid}.$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "mYiXOlyvoIiYs0VuDro4xC",
     "type": "MD"
    }
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend checking the hidden slides in tutorial 1 before approaching these exercises."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "soZCVUP0PzcQexv4G9bDRg",
     "type": "MD"
    }
   },
   "source": [
    "## I. Softmax Derivative (5pt)\n",
    "\n",
    "Derive the gradients of the softmax function and demonstrate how the expression can be reformulated solely by using the softmax function, i.e., in some expression where only $\\text{softmax}(x)$, but not $x$, is present. Recall that the softmax function is defined as follows:\n",
    "\n",
    "$$\\text{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "IpqCRRTyHjo6KCJA6LIqmx",
     "type": "MD"
    }
   },
   "source": [
    "### I. Softmax Derivative - Answer:\n",
    "$$\\frac{\\partial softmax(x)_i}{\\partial x_k} = \\text{...}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "qm487O2HSrGtnaEuKf0Yet",
     "type": "MD"
    }
   },
   "source": [
    "## II. Cross-Entropy Gradient (5pt)\n",
    "\n",
    "Derive the gradient of cross-entropy loss with regard to the inputs of a softmax function. i.e., find the gradients with respect to the softmax input vector $\\theta$, when the prediction is denoted by $\\hat{y} = \\text{softmax}(\\theta)$. Remember the cross entropy function is:\n",
    "$$CE(y, \\hat{y}) = -\\sum_i y_i log(\\hat{y_i})$$\n",
    "\n",
    "\n",
    "where $y$ is the one-hot label vector, and $\\hat{y}$ is the predicted probability vector for all classes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "k0wyAAwjcE9zeKFTRfYW0U",
     "type": "MD"
    }
   },
   "source": [
    "### II. Cross-Entropy Gradient - Answer\n",
    "\n",
    "<!--- write your answer -->\n",
    "$$\\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta} = \\text{Go for it}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "XXTewYlH5FSAKliEp1LYVr",
     "type": "MD"
    }
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "eU1spAtEoWOmiuz8b1epc6",
     "type": "MD"
    }
   },
   "source": [
    "## I. Derivative Of Activation Functions (5pt)\n",
    "\n",
    "The following cell contains an implementation of some activation functions. Implement the corresponding derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "KnegWR2iltc4XwyJw0Fdw3",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.div(torch.exp(x) - torch.exp(-x), torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = torch.exp(x.T - torch.max(x, dim=-1).values).T  # Subtracting max(x) for numerical stability\n",
    "    return exp_x / exp_x.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "maCkjVZ0dIFKS1IPadow46",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def d_sigmoid(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_tanh(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_softmax(x):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "GaitupBIkrSaDCvQc5buP5",
     "type": "MD"
    }
   },
   "source": [
    "## II. Train a Fully Connected network on MNIST (30pt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "An2t0OVJDND2S2KElPOtHf",
     "type": "MD"
    }
   },
   "source": [
    "In the following exercise, you will create a classifier for the MNIST dataset.\n",
    "You should write your own training and evaluation code and meet the following\n",
    "constraints:\n",
    "<ul>\n",
    "<li> You are only allowed to use torch tensor manipulations.</li>\n",
    "<li> You are NOT allowed to use:\n",
    "  <ul>\n",
    "  <li> Auto-differentiation - backward()</li>\n",
    "  <li> Built-in loss functions</li>\n",
    "  <li> Built-in activations</li>\n",
    "  <li> Built-in optimization</li>\n",
    "  <li> Built-in layers (torch.nn)</li>\n",
    "  </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "RJnSAOesGYsgF2m9BMUfzK",
     "type": "MD"
    }
   },
   "source": [
    "a. The required classifier class is defined.\n",
    "\n",
    "You should implement the forward and backward passes of the model.\n",
    "Train the model and plot the model's accuracy and loss (both on train and test sets) as a function of the epochs.\n",
    "You should save the model's weights and biases. Change the student_ids to yours.\n",
    "\n",
    "In this section, you <b>must</b> use the \"set_seed\" function with the given seed and <b>sigmoid</b> as an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "aJySKnlSpLwCl0eoJYCaFN",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "SEED = 42\n",
    "EPOCHS = 16\n",
    "BATCH_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "# Setting seed\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "# Transformation for the data\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torch.flatten])\n",
    "\n",
    "\n",
    "# Cross-Entropy loss implementation\n",
    "def one_hot(y, num_of_classes=10):\n",
    "    hot = torch.zeros((y.size()[0], num_of_classes))\n",
    "    hot[torch.arange(y.size()[0]), y] = 1\n",
    "    return hot\n",
    "\n",
    "def cross_entropy(y, y_hat):\n",
    "    return -torch.sum(one_hot(y) * torch.log(y_hat)) / y.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "lo57lFKyOqQmMGfLR0Meso",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "nuoAPQXRzhYGwelAr4CeWe",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork:\n",
    "    def __init__(self, input_size, output_size, hidden_size1, activiation_func, lr=0.01):\n",
    "        # parameters\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "\n",
    "        # activation function\n",
    "        self.activation_func = activiation_func\n",
    "\n",
    "        # weights\n",
    "        self.W1 = torch.randn(self.input_size, self.hidden_size1)\n",
    "        self.b1 = torch.zeros(self.hidden_size1)\n",
    "\n",
    "        self.W2 = torch.randn(self.hidden_size1, self.output_size)\n",
    "        self.b2 = torch.zeros(self.output_size)\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, x, y, y_hat):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "9KzKsJARUjbine4dVjkfg2",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "model = FullyConnectedNetwork(784, 10, 128, sigmoid, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Mb57Mq1FFlv4rrr7hinJlz",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Write a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "oNEyQXyvcWyjxSQwcivnEJ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "students_ids = \"12345789_987654321\"\n",
    "torch.save({\"W1\": model.W1, \"W2\": model.W2, \"b1\": model.b1, \"b2\": model.b2}, f\"HW1_{students_ids}.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "bLjHSOjQThjOLvJ8hOgvr6",
     "type": "MD"
    }
   },
   "source": [
    "b. Train the model with various learning rates (at least 3).\n",
    "\n",
    "Plot the model's accuracy and loss (both on train and test sets) as a function of the epochs.\n",
    "Discuss the differences in training with different learning rates. Support your answer with plots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "8qd1yAbzAT1xIRQtWUUHoY",
     "type": "MD"
    }
   },
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend using GPUs to solve this section. You can use free GPUs provided by Google Colab or by Kaggle (instructions on how to connect are in Moodle). Also, we recommend going over all tutorial notebooks and using dropout, normalization and Adam for better learning. Solving this on your personal computer will be significantly slower than using cloud computation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WC7InslhxyIvCc38ESrBDr",
     "type": "MD"
    }
   },
   "source": [
    "## I. Implement and Train a CNN (30pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever Ben sees a cat, his first instinct is to run up and pet them. However, after a recent incident he realized not all types of cats are very fond of that type of attention. Train a classifier to tell the difference between different types of big cats, and help Ben from putting himself in too much danger.\n",
    "\n",
    "Your code should meet the following constraints:\n",
    "\n",
    "1. Your classifier must be CNN based.\n",
    "2. You are not allowed to use any pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stages\n",
    "1. Perform a short EDA (Exploratory Data Analysis).\n",
    "2. Train the model and plot its accuracy and loss (for both the training and validation sets) as a function of the epochs. Display the overall number of parameters in the model. To see the number of parameters in your model, run `sum(p.numel() for p in model.parameters())`.\n",
    "3. Report the test set accuracy.\n",
    "\n",
    " Your data is in `hw1_data/big_cats`.\n",
    "\n",
    "You can use the provided code for preprocessing the data. You can also define a custom dataset (as in tutorial 3) or use `torchvision.datasets.ImageFolder` if you prefer. **Your training function must call the `set_seed` command for reproducibility**.\n",
    "\n",
    " #### Submission\n",
    "In addition to the code in the notebook, you should submit:\n",
    "\n",
    "1. a `.py` file containing your model class.\n",
    "2. a `.pkl` file containing the weight of your model.\n",
    "\n",
    "#### Grading\n",
    "- 5 points for EDA.\n",
    "- 15 points based on reaching minimum test accuracy (77% accuracy required to get all 15 points, 70% accuracy to get 10 points).\n",
    "- 10 points competitive: try to balance the tradeoff between number of parameters in your model and model's test accuracy. The lower the # of parameters and the higher the test accuracy, the higher the final score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class BigCatDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])  # You can add more transformations if needed\n",
    "        classes = [os.path.join(root_dir, c) for c in os.listdir(root_dir)]  # Assumes images are stored in class-named subdirectories. You will need to convert this to a tensor when training.\n",
    "        self.data = [os.path.join(c, d) for c in classes for d in os.listdir(c)]\n",
    "        self.classes = [c.split('/')[-1] for c in classes]\n",
    "        self.classes.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        img_class = self.classes.index(img_path.split('/')[-2])\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img)\n",
    "        return img, img_class\n",
    "\n",
    "    def get_class(self, i):\n",
    "        return self.classes[i]\n",
    "\n",
    "\n",
    "# Creating datasets: In your code, create dataloaders from these datasets for training, validation, and testing.\n",
    "train = BigCatDataset('/PATH/TO/DATASET/train')\n",
    "val = BigCatDataset('/PATH/TO/DATASET/valid')\n",
    "test = BigCatDataset('/PATH/TO/DATASET/test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Fq3Hl4TmKAzC5Xw1b7iBpZ",
     "type": "MD"
    }
   },
   "source": [
    "## II. Analyzing a Pre-trained CNN (Filters) (10pt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "1KKmAN8YX0fDzOJct7vTn4",
     "type": "MD"
    }
   },
   "source": [
    "In this part, you are going to analyze a (large) pre-trained model. Pre-trained models are quite popular these days, as big companies can train really large models on large datasets (something that personal users can't do as they lack the sufficient hardware). These pre-trained models can be used to fine-tune on other/small datasets or used as components in other tasks (like using a pre-trained classifier for object detection).\n",
    "\n",
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
    "\n",
    "You can use the following transform to normalize:\n",
    "\n",
    "`normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])`\n",
    "<a href=\"https://pytorch.org/vision/stable/models.html\">Read more here</a>\n",
    "\n",
    "\n",
    "1. Load a pre-trained VGG16 with PyTorch using `torchvision.models.vgg16(pretrained=True, progress=True, **kwargs)` (<a href=\"https://pytorch.org/vision/stable/models.html#classification\">read more here</a>). Don't forget to use the model in evaluation mode (`model.eval()`).\n",
    "\n",
    "2. Load the images in the `hw1_data/birds` folder and display them.\n",
    "\n",
    "3. Pre-process the images to fit VGG16's architecture. What steps did you take?\n",
    "\n",
    "4. Feed the images (forward pass) to the model. What are the outputs?\n",
    "\n",
    "5. Choose an image of a dog in the `hw1_data/dogs` folder, display it and feed it to network. What are the outputs?\n",
    "\n",
    "6. For the first 3 filters in the first layer of VGG16, plot their response (their output) for the image from section 5. Explain what do you see."
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "argmax-flows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
